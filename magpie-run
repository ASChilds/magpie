#!/bin/bash
#############################################################################
#  Copyright (C) 2013-2015 Lawrence Livermore National Security, LLC.
#  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).
#  Written by Albert Chu <chu11@llnl.gov>
#  LLNL-CODE-644248
#  
#  This file is part of Magpie, scripts for running Hadoop on
#  traditional HPC systems.  For details, see https://github.com/llnl/magpie.
#  
#  Magpie is free software; you can redistribute it and/or modify it
#  under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 of the License, or
#  (at your option) any later version.
#  
#  Magpie is distributed in the hope that it will be useful, but
#  WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
#  General Public License for more details.
#  
#  You should have received a copy of the GNU General Public License
#  along with Magpie.  If not, see <http://www.gnu.org/licenses/>.
#############################################################################

# This script is the core processing script for setting up daemons and
# running jobs.  For the most part, it shouldn't be editted.  See
# job submission files for configuration details.

source ${MAGPIE_SCRIPTS_HOME}/magpie-exports-submission-type
source ${MAGPIE_SCRIPTS_HOME}/magpie-exports-core
source ${MAGPIE_SCRIPTS_HOME}/magpie-exports-job-dependent
source ${MAGPIE_SCRIPTS_HOME}/magpie-lib-core
source ${MAGPIE_SCRIPTS_HOME}/magpie-lib-hadoop-filesystem
source ${MAGPIE_SCRIPTS_HOME}/magpie-lib-job-management
source ${MAGPIE_SCRIPTS_HOME}/magpie-lib-local-dirs-conversion

source ${MAGPIE_SCRIPTS_HOME}/magpie-run-project-hadoop
source ${MAGPIE_SCRIPTS_HOME}/magpie-run-project-hbase
source ${MAGPIE_SCRIPTS_HOME}/magpie-run-project-kafka
source ${MAGPIE_SCRIPTS_HOME}/magpie-run-project-mahout
source ${MAGPIE_SCRIPTS_HOME}/magpie-run-project-pig
source ${MAGPIE_SCRIPTS_HOME}/magpie-run-project-phoenix
source ${MAGPIE_SCRIPTS_HOME}/magpie-run-project-spark
source ${MAGPIE_SCRIPTS_HOME}/magpie-run-project-storm
source ${MAGPIE_SCRIPTS_HOME}/magpie-run-project-tachyon
source ${MAGPIE_SCRIPTS_HOME}/magpie-run-project-zeppelin
source ${MAGPIE_SCRIPTS_HOME}/magpie-run-project-zookeeper

if ! Magpie_am_I_master
then
    exit 0
fi

# Initially make variables specific to node
Magpie_make_all_local_dirs_node_specific

# Output some general info
echo "*******************************************************"
echo "* Magpie General Job Info"
echo "*"
echo "* Job Nodelist: ${MAGPIE_NODELIST}"
echo "* Job Nodecount: ${MAGPIE_NODE_COUNT}"
echo "* Job Timelimit in Minutes: ${MAGPIE_TIMELIMIT_MINUTES}"
echo "* Job Name: ${MAGPIE_JOB_NAME}"
echo "* Job ID: ${MAGPIE_JOB_ID}"
echo "*"
echo "*******************************************************"

if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT_SHELL}X" != "X" ]
then
    MAGPIE_SHELL="${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT_SHELL}"
else
    MAGPIE_SHELL="${SHELL}"
fi

if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
then
    if [ -f "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}" ]
    then
        rm -f ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    fi
    
    touch ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    chmod 700 ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}

    echo "#!${MAGPIE_SHELL}" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}

    echo "# Common environment variables for Job = ${MAGPIE_JOB_NAME}, Job ID = ${MAGPIE_JOB_ID}" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}

    echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    if [ "${JAVA_HOME}X" != "X" ]
    then
        if echo $MAGPIE_SHELL | grep -q csh
        then
            echo "setenv JAVA_HOME \"${JAVA_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
        else
            echo "export JAVA_HOME=\"${JAVA_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
        fi
        echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    fi
fi

# Global flag for setup check, will be set to false if any startup fails
prior_setup_successful=true

# Global, will be set/adjusted by various start functions
totalsleepwait=0

# Zookeeper setup must come first, as other things like Hbase & Storm require it
# Will set zookeeper_should_be_torndown & zookeeper_setup_successful appropriately
Magpie_run_start_zookeeper

# Will set hadoop_should_be_torndown & hadoop_setup_successful appropriately
Magpie_run_start_hadoop

# After Hadoop setup, requires Hadoop
Magpie_run_start_pig
# After Hadoop setup, requires Hadoop
Magpie_run_start_mahout

# After Zookeeper setup, requires Zookeeper
# Will set hbase_should_be_torndown & hbase_setup_successful appropriately
Magpie_run_start_hbase

# After Hbase setup, requires Hbase
# Will set phoenix_should_be_torndown & phoenix_setup_successful appropriately
Magpie_run_start_phoenix

# Will set spark_should_be_torndown & spark_setup_successful appropriately
Magpie_run_start_spark

# Will set kafka_should_be_torndown & kafka_setup_successful appropriately
Magpie_run_start_kafka

# After Spark setup, requires Spark
# Will set zeppelin_should_be_torndown & zeppelin_setup_successful appropriately
Magpie_run_start_zeppelin

# After Zookeeper setup, requires Zookeeper
# Will set storm_should_be_torndown & storm_setup_successful appropriately
Magpie_run_start_storm

# After Hadoop setup, requires HDFS for formatting
# Will set tachyon_should_be_torndown & tachyon_setup_successful appropriately
Magpie_run_start_tachyon

# Make sure all setup passed
if [ "${zookeeper_setup_successful}" == "1" ] \
    && [ "${hadoop_setup_successful}" == "1" ] \
    && [ "${hbase_setup_successful}" == "1" ] \
    && [ "${phoenix_setup_successful}" == "1" ] \
    && [ "${spark_setup_successful}" == "1" ] \
    && [ "${kafka_setup_successful}" == "1" ] \
    && [ "${zeppelin_setup_successful}" == "1" ] \
    && [ "${storm_setup_successful}" == "1" ] \
    && [ "${tachyon_setup_successful}" == "1" ]
then
    if [ "${MAGPIE_JOB_TYPE}" == "script" ]
    then
        echo "*******************************************************"
        echo "* Executing script $MAGPIE_SCRIPT_PATH $MAGPIE_SCRIPT_ARGS"
        echo "*******************************************************"
        ${MAGPIE_SCRIPTS_HOME}/magpie-run-execute script ${MAGPIE_SCRIPT_PATH} ${MAGPIE_SCRIPT_ARGS} &
        scriptpid=$!
        Magpie_wait_script_sigusr2_on_job_timeout ${scriptpid}
    elif [ "${MAGPIE_JOB_TYPE}" == "interactive" ]
    then
        echo "*******************************************************"
        echo "* Entering Magpie ${MAGPIE_JOB_TYPE} mode"
        echo "*******************************************************"
        ${MAGPIE_SCRIPTS_HOME}/magpie-run-execute interactive &
        scriptpid=$!
        wait $scriptpid
    elif [ "${MAGPIE_JOB_TYPE}" == "pig" ]
    then
        Magpie_run_pig
    elif [ "${MAGPIE_JOB_TYPE}" == "mahout" ]
    then
        Magpie_run_mahout
    elif [ "${MAGPIE_JOB_TYPE}" == "hadoop" ]
    then
        Magpie_run_hadoop
    elif [ "${MAGPIE_JOB_TYPE}" == "hbase" ]
    then
        Magpie_run_hbase
    elif [ "${MAGPIE_JOB_TYPE}" == "phoenix" ]
    then
        Magpie_run_phoenix
    elif [ "${MAGPIE_JOB_TYPE}" == "spark" ]
    then
        Magpie_run_spark
    elif [ "${MAGPIE_JOB_TYPE}" == "kafka" ]
    then
        Magpie_run_kafka
    elif [ "${MAGPIE_JOB_TYPE}" == "zeppelin" ]
    then
        Magpie_run_zeppelin
    elif [ "${MAGPIE_JOB_TYPE}" == "storm" ]
    then
        Magpie_run_storm
    elif [ "${MAGPIE_JOB_TYPE}" == "tachyon" ]
    then
        Magpie_run_tachyon
    elif [ "${MAGPIE_JOB_TYPE}" == "zookeeper" ]
    then
        Magpie_run_zookeeper
    elif [ "${MAGPIE_JOB_TYPE}" == "testall" ]
    then
        echo "*******************************************************"
        echo "* Running Magpie TestAll"
        echo "*******************************************************"
        ${MAGPIE_SCRIPTS_HOME}/magpie-run-execute script ${MAGPIE_SCRIPTS_HOME}/magpie-run-job-magpie-testall &
        scriptpid=$!
        Magpie_wait_script_sigusr2_on_job_timeout ${scriptpid}
    fi
fi

# Tachyon before Hadoop shutdown, may need to flush
# Sets tachyon_teardown_complete if teardown done
Magpie_run_stop_tachyon

# Sets storm_teardown_complete if teardown done
Magpie_run_stop_storm

# Before Spark, depends on Spark
# Sets zeppelin_teardown_complete if teardown done
Magpie_run_stop_zeppelin

# Sets kafka_teardown_complete if teardown done
Magpie_run_stop_kafka

# Sets spark_teardown_complete if teardown done
Magpie_run_stop_spark

# Before Hbase, depends on Hbase
# Sets phoenix_teardown_complete if teardown done
Magpie_run_stop_phoenix

# Sets hbase_teardown_complete if teardown done
Magpie_run_stop_hbase

# Sets hadoop_teardown_complete if teardown done
Magpie_run_stop_hadoop

# Zookeeper teardown comes last, as other things like Hbase & Storm require it
# Sets zookeeper_teardown_complete if teardown done
Magpie_run_stop_zookeeper

exit 0

