#!/bin/bash
#############################################################################
#  Copyright (C) 2013 Lawrence Livermore National Security, LLC.
#  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).
#  Written by Albert Chu <chu11@llnl.gov>
#  LLNL-CODE-644248
#  
#  This file is part of Magpie, scripts for running Hadoop on
#  traditional HPC systems.  For details, see <URL>.
#  
#  Magpie is free software; you can redistribute it and/or modify it
#  under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 of the License, or
#  (at your option) any later version.
#  
#  Magpie is distributed in the hope that it will be useful, but
#  WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
#  General Public License for more details.
#  
#  You should have received a copy of the GNU General Public License
#  along with Magpie.  If not, see <http://www.gnu.org/licenses/>.
#############################################################################

# This script is the core processing script for running Hadoop jobs.
# For the most part, it shouldn't be editted.  See magpie.sbatch for
# configuration details.

source ${MAGPIE_SCRIPTS_HOME}/magpie-common-exports

if [ "${HADOOP_SETUP_TYPE}" == "MR1" ] || [ "${HADOOP_SETUP_TYPE}" == "HDFS1" ]
then
    scriptprefix="bin"
    terasortexamples="hadoop-examples-$HADOOP_VERSION.jar"
    rmoption="-rmr"
elif [ "${HADOOP_SETUP_TYPE}" == "MR2" ] || [ "${HADOOP_SETUP_TYPE}" == "HDFS2" ]
then
    scriptprefix="sbin"
    terasortexamples="share/hadoop/mapreduce/hadoop-mapreduce-examples-$HADOOP_VERSION.jar"
    rmoption="-rm -r"
fi
remotecmd="${MAGPIE_REMOTE_CMD:=ssh}" 

if Magpie_am_I_a_hadoop_master
then

# Setup/Run ZooKeeper
#
# We start this first, as Hadoop jobs may require Zookeeper
#

    if [ "${ZOOKEEPER_SETUP}" == "yes" ]
    then
	if [ "${ZOOKEEPER_MODE}" == "setuponly" ]
	then
	    echo "*******************************************************"
	    echo "*"
	    echo "* To start Zookeper, on each node"
	    echo "*   Set ZOOCFGDIR, such as ..."
	    echo "*     export ZOOCFGDIR=\"${ZOOCFGDIR}\""
	    echo "*     or"
	    echo "*     setenv ZOOCFGDIR \"${ZOOCFGDIR}\""
	    echo "*   cd $ZOOKEEPER_HOME"
	    echo "*   bin/zkServer.sh start"
	    echo "*" 
	    echo "*   to end"
	    echo "*" 
	    echo "*   bin/zkServer.sh stop"
	    echo "*" 
	    echo "*******************************************************"
	else
	    zookeepernodes=`cat ${ZOOKEEPER_CONF_DIR}/zookeeper_slaves`
	    
	    for zookeepernode in ${zookeepernodes}
	    do
		${remotecmd} ${MAGPIE_REMOTE_CMD_OPTS} ${zookeepernode} ${MAGPIE_SCRIPTS_HOME}/bin/magpie-launch-zookeeper.sh ${ZOOKEEPER_CONF_DIR} ${ZOOKEEPER_HOME} start
	    done
	fi
    fi

#
# Setup/Run Hadoop
#

    cd ${HADOOP_HOME}

    if [ ${HADOOP_MODE} != "setuponly" ]
    then
	echo "Starting hadoop"
	if [ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ]
	then
	    ${scriptprefix}/start-dfs.sh 
	fi
	
	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	then
	    ${scriptprefix}/start-mapred.sh
	fi
	
	if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    ${scriptprefix}/start-yarn.sh
	fi

	# My rough estimate for setup time is 30 seconds per 64 nodes
	sleepwait=`expr ${HADOOP_SLAVE_COUNT} \/ 64 \* 30`
	if [ ${sleepwait} -lt 30 ]
	then
	    sleepwait=30
	fi
	echo "Waiting ${sleepwait} seconds to allows daemons to setup"
	sleep ${sleepwait}

	echo "*******************************************************"
	echo "*"
	echo "* You can view your job/cluster status by launching a web browser and pointing to ..."
	echo "*"
	if [ ${HADOOP_SETUP_TYPE}  == "MR1" ]
	then
	    echo "* Jobtracker: http://${HADOOP_MASTER_NODE}:50030"
	elif [ ${HADOOP_SETUP_TYPE}  == "MR2" ]
	then
	    echo "* Yarn Resource Manager: http://${HADOOP_MASTER_NODE}:8088"
	fi
	echo "*" 
	echo "* HDFS Namenode: http://${HADOOP_MASTER_NODE}:50070"
	echo "*"
	echo "* To interact with Hadoop:"
	echo "*   ${remotecmd} ${HADOOP_MASTER_NODE}"
	echo "*   Set HADOOP_CONF_DIR, such as ..."
	echo "*     export HADOOP_CONF_DIR=\"${HADOOP_CONF_DIR}\""
	echo "*     or"
	echo "*     setenv HADOOP_CONF_DIR \"${HADOOP_CONF_DIR}\""
	echo "*   cd $HADOOP_HOME"
	echo "*" 
	echo "*   then do as you please, e.g. bin/hadoop fs ..."
	echo "*" 
	echo "*   To end your session early, kill the daemons via:"
	if [ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ]
	then
            echo "*   ${scriptprefix}/stop-dfs.sh"
	fi
	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	then
	    echo "*   ${scriptprefix}/stop-mapred.sh"
	fi
	if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    echo "*   ${scriptprefix}/stop-yarn.sh"
	fi
	echo "*******************************************************"
    fi

    if ([ "${HADOOP_SETUP_TYPE}" == "MR1" ] \
	|| [ "${HADOOP_SETUP_TYPE}" == "MR2" ]) \
	&& [ "${HADOOP_MODE}" == "terasort" ]
    then
	echo "*******************************************************"
	echo "* Running Terasort"
	echo "*******************************************************"

	if [ "${HADOOP_TERASORT_SIZE}X" == "X" ]
	then
	    terasortsize=50000000
	else
	    terasortsize=$HADOOP_TERASORT_SIZE
	fi

	if [ "${HADOOP_FILESYSTEM_MODE}" == "rawnetworkfs" ]
	then
	    pathprefix="${HADOOP_RAWNETWORKFS_PATH}/"
	elif [ "${HADOOP_FILESYSTEM_MODE}" == "intellustre" ]
	then
	    pathprefix="${HADOOP_INTELLUSTRE_PATH}/"
	fi

	if [ "${HADOOP_TERASORT_CLEAR_CACHE}X" != "X" ]
	then
	    if [ "${HADOOP_TERASORT_CLEAR_CACHE}" == "yes" ]
	    then
		clearcache="-Ddfs.datanode.drop.cache.behind.reads=true -Ddfs.datanode.drop.cache.behind.writes=true"
	    else
		clearcache=""
	    fi
	else
	    clearcache="-Ddfs.datanode.drop.cache.behind.reads=true -Ddfs.datanode.drop.cache.behind.writes=true"
	fi

	cd ${HADOOP_HOME}

	command="bin/hadoop jar ${terasortexamples} teragen ${clearcache} $terasortsize ${pathprefix}terasort-teragen"
	echo "Running $command" >&2
	$command
	
	sleep 30
	
	if [ "${HADOOP_TERASORT_REDUCER_COUNT:-0}" -ne "0" ]
	then
	    rtasks=$HADOOP_TERASORT_REDUCER_COUNT
	else
	    rtasks=`expr $HADOOP_SLAVE_COUNT \* 2`
	fi

	command="bin/hadoop jar ${terasortexamples} terasort -Dmapred.reduce.tasks=$rtasks -Ddfs.replication=1 ${clearcache} ${pathprefix}terasort-teragen ${pathprefix}terasort-sort"
	
	echo "Running $command" >&2
	$command

	command="bin/hadoop fs ${rmoption} ${pathprefix}terasort-teragen"
	$command
	command="bin/hadoop fs ${rmoption} ${pathprefix}terasort-sort"
	$command
    elif [ "${HADOOP_MODE}" == "script" ]
    then
	echo "*******************************************************"
	echo "* Executing script $HADOOP_SCRIPT_PATH"
	echo "*******************************************************"
	${HADOOP_SCRIPT_PATH}
    elif [ "${HADOOP_MODE}" == "interactive" ] \
	|| [ "${HADOOP_MODE}" == "setuponly" ]
    then
	echo "*******************************************************"
	echo "* Entering Hadoop ${HADOOP_MODE} mode"
	echo "*"

	if [ "${HADOOP_MODE}" == "setuponly" ]
	then
	    echo "* To setup, you likely want to goto:"
	    echo "*   ${remotecmd} ${HADOOP_MASTER_NODE}"
	    echo "*   Set HADOOP_CONF_DIR, such as ..."
	    echo "*     export HADOOP_CONF_DIR=\"${HADOOP_CONF_DIR}\""
	    echo "*     or"
	    echo "*     setenv HADOOP_CONF_DIR \"${HADOOP_CONF_DIR}\""
	    echo "*   cd $HADOOP_HOME"
	    echo "*"
	    echo "* You probably want to run run:" 
	    echo "*"
	    if [ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
		|| [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ]
	    then
		echo "*   ${scriptprefix}/start-dfs.sh" 
	    fi
	    
	    if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	    then
		echo "*   ${scriptprefix}/start-mapred.sh"
	    fi
	
	    if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	    then
		echo "*   ${scriptprefix}/start-yarn.sh"
	    fi
	    echo "*"
	fi

	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ] || [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    echo "* To launch jobs:"
	    echo "*   ${remotecmd} ${HADOOP_MASTER_NODE}"
	    echo "*   Set HADOOP_CONF_DIR, such as ..."
	    echo "*     export HADOOP_CONF_DIR=\"${HADOOP_CONF_DIR}\""
	    echo "*     or"
	    echo "*     setenv HADOOP_CONF_DIR \"${HADOOP_CONF_DIR}\""
	    echo "*   cd $HADOOP_HOME"
	    echo "*   bin/hadoop jar ..."
	    echo "*" 
	fi
	
	if [ "${HADOOP_MODE}" == "setuponly" ]
	then
	    echo "*   To cleanup your session, kill deamons likely like:" 
	    if [ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
		|| [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ]
	    then
		echo "*   ${scriptprefix}/stop-dfs.sh"
	    fi
	    if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	    then
		echo "*   ${scriptprefix}/stop-mapred.sh"
	    fi
	    if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	    then
		echo "*   ${scriptprefix}/stop-yarn.sh"
	    fi
	fi
	echo "*" 
	echo "*******************************************************"
	hadoopsleepamount=`expr ${SBATCH_TIMELIMIT} - 5`
	hadoopsleepseconds=`expr ${hadoopsleepamount}  \* 60`
	sleep ${hadoopsleepseconds}
    fi

    cd ${HADOOP_HOME}

    if [ ${HADOOP_MODE} != "setuponly" ]
    then
	echo "Stopping hadoop"
	if [ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ]
	then
	    ${scriptprefix}/stop-dfs.sh 
	fi
	
	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	then
	    ${scriptprefix}/stop-mapred.sh
	fi
	
	if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    ${scriptprefix}/stop-yarn.sh
	fi
    fi
    
    if [ "${ZOOKEEPER_SETUP}" == "yes" ]
    then
	if [ "${ZOOKEEPER_MODE}" != "setuponly" ]
	then
	    zookeepernodes=`cat ${ZOOKEEPER_CONF_DIR}/zookeeper_slaves`
	    
	    for zookeepernode in ${zookeepernodes}
	    do
		${remotecmd} ${MAGPIE_REMOTE_CMD_OPTS} ${zookeepernode} ${MAGPIE_SCRIPTS_HOME}/bin/magpie-launch-zookeeper.sh ${ZOOKEEPER_CONF_DIR} ${ZOOKEEPER_HOME} stop
	    done
	fi
    fi
fi

exit 0

