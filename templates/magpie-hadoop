############################################################################
# Hadoop Core Configurations
############################################################################

# Should Hadoop be run
#
# Specify yes or no.  Defaults to no.
# 
export HADOOP_SETUP=no

# Set Hadoop Setup Type
#
# Will inform scripts on how to setup config files and what daemons to
# launch/setup.  The hadoop build/binaries set by HADOOP_HOME
# needs to match up with what you set here.
#
# MR1 - MapReduce/Hadoop 1.0 w/ HDFS
# MR2 - MapReduce/Hadoop 2.0 w/ HDFS
# HDFS1 - HDFS only w/ Hadoop 1.0 
# HDFS2 - HDFS only w/ Hadoop 2.0
#
# Note that the HDFS only options are normally for convenience,
# perhaps to move files in/out of HDFS.  It only works with the
# HADOOP_FILESYSTEM_MODE of hdfs or hdfsoverlustre.  It makes no sense
# otherwise.
#
export HADOOP_SETUP_TYPE="MR2"

# Version
#
# Make sure the version for Mapreduce version 1 or 2 matches whatever
# you set in HADOOP_SETUP_TYPE
#
export HADOOP_VERSION="2.2.0"

# Path to your Hadoop build/binaries
#
# Make sure the build for Mapredeuce version 1 or 2 matches whatever
# you set in HADOOP_SETUP_TYPE.
#
# This should be accessible on all nodes in your allocation. Typically
# this is in an NFS mount.
#
export HADOOP_HOME="/home/username/hadoop-${HADOOP_VERSION}"

# Path local to each cluster node, typically something in /tmp.
# This will store local conf files and log files for your job. 
#
# This will not be used for storing intermediate files or
# distributedcache files.  See HADOOP_LOCALSTORE above for that.
#
export HADOOP_LOCAL_DIR="/tmp/username/hadoop"

# Directory where Hadoop configuration templates are stored
#
# If not specified, assumed to be $MAGPIE_SCRIPTS_HOME/conf
#
# export HADOOP_CONF_FILES="${MAGPIE_SCRIPTS_HOME}/conf"

# Daemon Heap Max
#
# Heap maximum for Hadoop daemons (i.e. Resource Manger, NodeManager,
# etc.), specified in megs.
#
# If not specified, defaults to 1000 (which is Hadoop default)
#
# May need to be increased if you are scaling large, get OutofMemory
# errors, or perhaps have a lot of cores on a node.
#
# export HADOOP_DAEMON_HEAP_MAX=2000

############################################################################
# Hadoop Job/Run Configurations
############################################################################

# Set how Hadoop should run
#
# "terasort" - run terasort.  Useful for making sure things are setup
#              the way you like.
#
# "script" - execute a script that lists all of your Hadoop jobs.  Be
#            sure to set HADOOP_SCRIPT_PATH to your script.
#
# "interactive" - manually interact to submit jobs, peruse HDFS, etc.
#                 also useful for moving data in/out of HDFS.  In this
#                 mode you'll login to the cluster node that is your
#                 'master' node and interact with Hadoop directly
#                 (e.g. bin/hadoop ...)
#
# "setuponly" - Like 'interactive' but only setup conf files. useful
#               if user wants to setup daemons themselves, etc.
#
export HADOOP_MODE="terasort"

# Tasks per Node
#
# If not specified, defaults to #cores * 1.5.  # of cores is determined
# by /proc/cpuinfo.  Adjustment may be needed if hyperthreading is enabled.
#
# export HADOOP_MAX_TASKS_PER_NODE=8

# Default Map tasks for Job
#
# If not specified, defaults to HADOOP_MAX_TASKS_PER_NODE * compute
# nodes.
#
# export HADOOP_DEFAULT_MAP_TASKS=8

# Default Reduce tasks for Job
#
# If not specified, defaults to # compute nodes (i.e. 1 reducer per
# node)
#
# export HADOOP_DEFAULT_REDUCE_TASKS=8

# Max Map tasks for Task Tracker
#
# If not specified, defaults to HADOOP_MAX_TASKS_PER_NODE
#
# export HADOOP_MAX_MAP_TASKS=8

# Max Reduce tasks for Task Tracker
#
# If not specified, defaults to HADOOP_MAX_TASKS_PER_NODE
#
# export HADOOP_MAX_REDUCE_TASKS=8

# Heap size for JVM 
#
# Specified in M.  If not specified, a reasonable estimate will be
# calculated based on total memory available and number of CPUs on the
# system.
#
# HADOOP_CHILD_MAP_HEAPSIZE and HADOOP_CHILD_REDUCE_HEAPSIZE are for
# Yarn (i.e. HADOOP_SETUP_TYPE = MR2)
#
# If HADOOP_CHILD_MAP_HEAPSIZE and/or HADOOP_CHILD_REDUCE_HEAPSIZE are
# not specified, they are assumed to be HADOOP_CHILD_HEAPSIZE.
#
# export HADOOP_CHILD_HEAPSIZE=2048
# export HADOOP_CHILD_MAP_HEAPSIZE=2048
# export HADOOP_CHILD_REDUCE_HEAPSIZE=4096

# Container Buffer
#
# Specify the amount of overhead each Yarn container will have over
# the heap size.  Specified in M.  If not specified, a reasonable
# estimate will be calculated based on total memory available.
#
# export HADOOP_CHILD_MAP_CONTAINER_BUFFER=256
# export HADOOP_CHILD_REDUCE_CONTAINER_BUFFER=512

# Mapreduce Slowstart, indicating percent of maps that should complete
# before reducers begin.
#
# If not specified, defaults to 0.25 (Hadoop default is 0.05, really low)
#
# export HADOOP_MAPREDUCE_SLOWSTART=0.25

# Container Memory
#
# Memory on compute nodes for containers.  Typically "nice-chunk" less
# than actual memory on machine, b/c machine needs memory for its own
# needs (kernel, daemons, etc.).  Specified in megs.
#
# If not specified, a reasonable estimate will be calculated based on
# total memory on the system.
# export YARN_RESOURCE_MEMORY=32768

# Compression
#
# Should compression of outputs and intermediate data be enabled.
# Specify yes or no.
#
# Effectively, is time spend compressing data going to save you time
# on I/O.  Sometimes yes, sometimes no.
#
# export HADOOP_COMPRESSION=yes

# IO Sort Factors + MB
#
# The number of streams of files to sort while reducing and the memory
# amount to use while sorting.  This is a quite advanced mechanism
# taking into account many factors.  If not specified, some reasonable
# number will be assumed.
#
# export HADOOP_IO_SORT_FACTOR=10
# export HADOOP_IO_SORT_MB=100

# Parallel Copies
#
# The default number of parallel transfers run by reduce during the
# copy(shuffle) phase.  If not specified, some reasonable number will
# be assumed.
# export HADOOP_PARALLEL_COPIES=10

############################################################################
# Hadoop Terasort Configurations
############################################################################

# Terasort size
#
# For "terasort" mode.
#
# Specify 10000000000 for terabyte, for actual benchmarking
#
# Specify something small, like 50000000 for basic sanity tests.
# Defaults to 50000000.
#
# export HADOOP_TERASORT_SIZE=50000000

# Terasort reducer count
#
# For "terasort" mode.
#
# If not specified, will be compute node count * 2.
#
# export HADOOP_TERASORT_REDUCER_COUNT=4

# Terasort cache
#
# For "real benchmarking" you should flush page cache between a
# teragen and a terasort.  You can disable this for sanity runs/tests
# to make things go faster.  Specify yes or no.  Defaults to yes.
#
# export HADOOP_TERASORT_CLEAR_CACHE=no

############################################################################
# Hadoop Script Configurations
############################################################################

# Specify script to execute for "script" mode
#
# See hadoop-example-job-script for example of what to put in the script.
#
# export HADOOP_SCRIPT_PATH="${MAGPIE_SCRIPTS_HOME}/my-job-script"

############################################################################
# Hadoop Filesystem Mode Configurations
############################################################################

# Set how the filesystem should be setup
#
# "hdfs" - Normal straight up HDFS if you have local disk in your
#          cluster.  This option is primarily for benchmarking and
#          probably shouldn't be used in the general case.
#
#          Be careful running this in a cluster environment.  The next
#          time you execute your job, if a different set of nodes are
#          allocated to you, the HDFS data you wrote from a previous
#          job may not be there.  Using the --nodelist in sbatch may
#          be a way to alleviate this, if you work in an environment
#          where you have high confidence you will also get the same
#          nodes on each run.
#
# "hdfsoverlustre" - HDFS over Lustre.  See README for description.
#
# "hdfsovernetworkfs" - HDFS over Network FS.  Identical to HDFS over
#                       Lustre, but filesystem agnostic.
#
# "rawnetworkfs" - Use Hadoop RawLocalFileSystem (i.e. file: scheme),
#           to use networked file system directly.  It could be a
#           Lustre mount or NFS mount.  Whatever you please.
#
# "intellustre" - Use the Lustre plugin developed by Intel for IDH.
#
# "magpienetworkfs" - Use the Magpie Network FS plugin.  See README for
#                     details.
#
export HADOOP_FILESYSTEM_MODE="hdfsoverlustre"

# Path for HDFS when using local disk
#
# If you want to specify multiple paths (such as multiple drives),
# make them comma separated (e.g. /dir1,/dir2,/dir3).  The multiple
# paths will be used for local intermediate data and HDFS.  The first
# path will also store daemon data, such as namenode or jobtracker
# data.
#
export HADOOP_HDFS_PATH="/ssd/username/"

# Lustre path to do Hadoop HDFS out of
#
# Note that different versions of Hadoop may not be compatible with
# your current HDFS data.  If you're going to switch around to
# different versions, perhaps set different paths for different data.
#
export HADOOP_HDFSOVERLUSTRE_PATH="/lustre/username/hdfsoverlustre/"

# Networkfs path to do Hadoop HDFS out of
#
# Note that different versions of Hadoop may not be compatible with
# your current HDFS data.  If you're going to switch around to
# different versions, perhaps set different paths for different data.
#
export HADOOP_HDFSOVERNETWORKFS_PATH="/networkfs/username/hdfsovernetworkfs/"

# Path for rawnetworkfs
#
# This path is used for creating local per-node paths.
#
export HADOOP_RAWNETWORKFS_PATH="/lustre/username/rawnetworkfs/"

# Path for intellustre 
#
export HADOOP_INTELLUSTRE_PATH="/lustre/username/intellustre/"

# Path for magpienetworkfs 
#
# This path must be an absolute path.
#
export HADOOP_MAGPIENETWORKFS_PATH="/lustre/username/magpienetworkfs/"

# If you have a local SSD, performance may be better to store
# intermediate data on it rather than Lustre (or some other networked
# fs).  If the below environment variable is specified, local
# intermediate data will be stored in the specified directory.
# Otherwise it will go to an appropriate directory in Lustre/networked
# FS.
#
# Be wary, local SSDs stores may have less space than HDDs or
# networked file systems.  It can be easy to run out of space.
#
# If you want to specify multiple paths (such as multiple drives),
# make them comma separated (e.g. /dir1,/dir2,/dir3).  The multiple
# paths will be used for local intermediate data.
#
# export HADOOP_LOCALSTORE="/ssd/username/localstore/"

# HDFS Block Size
#
# Commonly 134217728, 268435456, 536870912 (i.e. 128m, 256m, 512m)
#
# If not specified, defaults to 134217728
#
# export HADOOP_HDFS_BLOCKSIZE=134217728

# HDFS Replication
#
# HDFS commonly uses 3.  It's not necessary if doing HDFS over Lustre,
# but replication > 1 can help w/ Hadoop task scheduling and job read
# performance at the cost of increased disk usage and write
# performance.  Higher replication can also help with resilience if
# nodes fail.  You may wish to set this to < 3 or even 1 if you want
# to save space.
#
# If not specified, defaults to 3
#
# export HADOOP_HDFS_REPLICATION=3

# RawNetworkFS Block Size
#
# Commonly 33554432, 67108864, 134217728 (i.e. 32m, 64m, 128m)
#
# If not specified, defaults to 33554432
#
# export HADOOP_RAWNETWORKFS_BLOCKSIZE=33554432

# IntelLustre Block Size
#
# Commonly 134217728, 268435456, 536870912 (i.e. 128m, 256m, 512m)
#
# If not specified, defaults to 536870912
#
# export HADOOP_INTELLUSTRE_BLOCKSIZE=536870912

# IntelLustre Stripe Size
#
# If not specified, defaults to 33554432
#
# export HADOOP_INTELLUSTRE_STRIPESIZE=33554432

# IntelLustre Stripe Count
#
# If not specified, defaults to -1
#
# export HADOOP_INTELLUSTRE_STRIPECOUNT=-1

# IntelLustre Shuffle
#
# Utilize Lustre specific shuffling.  May improve performance of some
# jobs.  Specify yes or no.  Defaults to no.
#
# export HADOOP_INTELLUSTRE_SHUFFLE=no

# MagpieNetworkFS Block Size
#
# Commonly 33554432, 67108864, 134217728 (i.e. 32m, 64m, 128m)
#
# If not specified, defaults to 33554432
#
# export HADOOP_MAGPIENETWORKFS_BLOCKSIZE=33554432

############################################################################
# Hadoop Environment Configurations
############################################################################

# Environment Extra
#
# Specify extra environment information that should be passed into
# Hadoop.  This file will simply be appended into the hadoop-env.sh
# (and if appropriate) yarn-env.sh.
#
# By default, a reasonable estimate for max user processes and open
# file descriptors will be calculated and put into hadoop-env.sh (and
# if appropriate) yarn-env.sh.  However, it's always possible they may
# need to be set differently. Everyone's cluster/situation can be
# slightly different.
#
# See the example hadoop-example-environment extra for examples on
# what you can/should do with adding extra environment settings.
#
# export HADOOP_ENVIRONMENT_EXTRA_PATH="${MAGPIE_SCRIPTS_HOME}/hadoop-my-environment"
