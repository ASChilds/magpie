#!/bin/bash
#############################################################################
#  Copyright (C) 2013 Lawrence Livermore National Security, LLC.
#  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).
#  Written by Albert Chu <chu11@llnl.gov>
#  LLNL-CODE-644248
#  
#  This file is part of Magpie, scripts for running Hadoop on
#  traditional HPC systems.  For details, see <URL>.
#  
#  Magpie is free software; you can redistribute it and/or modify it
#  under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 of the License, or
#  (at your option) any later version.
#  
#  Magpie is distributed in the hope that it will be useful, but
#  WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
#  General Public License for more details.
#  
#  You should have received a copy of the GNU General Public License
#  along with Magpie.  If not, see <http://www.gnu.org/licenses/>.
#############################################################################

# Export environment variables we promised to export in documentation
#
# Export common functions
#
# This is used by scripts, don't edit this

Magpie_am_I_master () {
    local myhostname=`hostname`
    if [ ${HADOOP_SETUP} == "yes" ]
    then
	if grep -q -E "^${myhostname}$" ${HADOOP_CONF_DIR}/masters
	then 
	    return 0
	fi
    elif [ ${ZOOKEEPER_SETUP} == "yes" ]
    then
	if grep -q -E "^${myhostname}$" ${ZOOKEEPER_CONF_DIR}/masters
	then 
	    return 0
	fi
    fi
    return 1
}

Magpie_am_I_a_hadoop_node () {
    local myhostname=`hostname`
    if grep -q -E "^${myhostname}$" ${HADOOP_CONF_DIR}/slaves \
	|| grep -q -E "^${myhostname}$" ${HADOOP_CONF_DIR}/masters
    then 
	if grep -q -E "^${myhostname}$" ${HADOOP_CONF_DIR}/masters
	then
	    hadoopnoderank=0
	else
	    hadoopnoderank=`grep -n -E "^${myhostname}$" ${HADOOP_CONF_DIR}/slaves | awk --field-separator=':' '{print $1}'`
	fi
	return 0
    fi
    return 1
}

Magpie_am_I_a_zookeeper_node () {
    local myhostname=`hostname`
    if grep -q -E "^${myhostname}$" ${ZOOKEEPER_CONF_DIR}/zookeeper_slaves
    then 
	zookeepernoderank=`grep -n -E "^${myhostname}$" ${ZOOKEEPER_CONF_DIR}/zookeeper_slaves | awk --field-separator=':' '{print $1}'`
	return 0
    fi
    return 1
}

Magpie_wait_script () {
    scriptpid=$1

    scriptsleepamounttemp=`expr ${SBATCH_TIMELIMIT} - ${MAGPIE_STARTUP_TIME}`
    scriptsleepamount=`expr ${scriptsleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`

    # We sleep in 30 second chunks, so times 2
    scriptsleepiterations=`expr ${scriptsleepamount}  \* 2`
    scriptexitted=0
    for ((i = 1; i <= ${scriptsleepiterations}; i++)); do
	if kill -0 ${scriptpid} 2&> /dev/null
	then
	    sleep 30
	else
	    scriptexitted=1
	    break
	fi
    done

    if [ "${scriptexitted}" == "0" ]
    then
	kill ${scriptpid}
    fi
    return 0
}

export MAGPIE_CLUSTER_NODERANK="${SLURM_NODEID:=0}"
export MAGPIE_NODE_COUNT="${SLURM_NNODES}"

export MAGPIE_LOCAL_JOB_DIR=${MAGPIE_LOCAL_DIR}/${SLURM_JOB_NAME}/${SLURM_JOB_ID}

export HADOOP_LOCAL_JOB_DIR=${HADOOP_LOCAL_DIR}/${SLURM_JOB_NAME}/${SLURM_JOB_ID}
export HADOOP_CONF_DIR=${HADOOP_LOCAL_JOB_DIR}/conf
export HADOOP_LOG_DIR=${HADOOP_LOCAL_JOB_DIR}/log
# For jobhistoryserver
export HADOOP_MAPRED_HOME=${HADOOP_HOME}

export HADOOP_YARN_HOME=${HADOOP_HOME}
export YARN_CONF_DIR=${HADOOP_CONF_DIR}
export YARN_LOG_DIR=${HADOOP_LOG_DIR}

# Unsure if needed, read about these two online
export HADOOP_HDFS_HOME=${HADOOP_HOME}
export HADOOP_COMMON_HOME=${HADOOP_HOME}

export PIG_LOCAL_JOB_DIR=${PIG_LOCAL_DIR}/${SLURM_JOB_NAME}/${SLURM_JOB_ID}
export PIG_CONF_DIR=${PIG_LOCAL_JOB_DIR}/conf

export ZOOKEEPER_LOCAL_JOB_DIR=${ZOOKEEPER_LOCAL_DIR}/${SLURM_JOB_NAME}/${SLURM_JOB_ID}
export ZOOKEEPER_CONF_DIR=${ZOOKEEPER_LOCAL_JOB_DIR}/conf
export ZOOKEEPER_LOG_DIR=${ZOOKEEPER_LOCAL_JOB_DIR}/log

if [ "${MAGPIE_STARTUP_TIME}X" == "X" ]
then
    export MAGPIE_STARTUP_TIME=30
fi

if [ "${MAGPIE_SHUTDOWN_TIME}X" == "X" ]
then
    export MAGPIE_SHUTDOWN_TIME=15
fi

# In main script, if master/slaves haven't been created yet, environment
# variable set in there.

if [ -f "${HADOOP_CONF_DIR}/masters" ]
then 
     export HADOOP_MASTER_NODE=`head -1 ${HADOOP_CONF_DIR}/masters`
fi

if [ -f "${HADOOP_CONF_DIR}/slaves" ]
then
    export HADOOP_SLAVE_COUNT=`cat ${HADOOP_CONF_DIR}/slaves|wc -l`
fi

if [ "${HADOOP_SETUP_TYPE}" == "MR1" ] || [ "${HADOOP_SETUP_TYPE}" == "HDFS1" ]
then
    hadoopscriptprefix="bin"
    dfsadminscript="hadoop"
elif [ "${HADOOP_SETUP_TYPE}" == "MR2" ] || [ "${HADOOP_SETUP_TYPE}" == "HDFS2" ]
then
    hadoopscriptprefix="sbin"
    dfsadminscript="hdfs"
fi

magpieremotecmd="${MAGPIE_REMOTE_CMD:=ssh}" 
