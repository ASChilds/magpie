<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

<property>
  <name>mapreduce.task.io.sort.factor</name>
  <value>IOSORTFACTOR</value>
  <description>The number of streams to merge at once while sorting
  files.  This determines the number of open file handles.</description>
</property>

<property>
  <name>mapreduce.task.io.sort.mb</name>
  <value>IOSORTMB</value>
  <description>The total amount of buffer memory to use while sorting 
  files, in megabytes.  By default, gives each merge stream 1MB, which
  should minimize seeks.</description>
</property>

<property>
  <name>mapreduce.cluster.local.dir</name>
  <value>LOCALSTOREDIR</value>
  <description>The local directory where MapReduce stores intermediate
  data files.  May be a comma-separated list of
  directories on different devices in order to spread disk i/o.
  Directories that do not exist are ignored.
  </description>
</property>

<property>
  <name>mapreduce.jobtracker.system.dir</name>
  <value>${hadoop.tmp.dir}/mapred/system</value>
  <description>The directory where MapReduce stores control files.
  </description>
</property>

<property>
  <name>mapreduce.jobtracker.staging.root.dir</name>
  <value>${hadoop.tmp.dir}/mapred/staging</value>
  <description>The root of the staging area for users' job files
  In practice, this should be the directory where users' home 
  directories are located (usually /user)
  </description>
</property>

<property>
  <name>mapreduce.cluster.temp.dir</name>
  <value>${hadoop.tmp.dir}/mapred/temp</value>
  <description>A shared directory for temporary files.
  </description>
</property>

<property>
  <name>mapreduce.reduce.shuffle.parallelcopies</name>
  <value>MRPRALLELCOPIES</value>
  <description>The default number of parallel transfers run by reduce
  during the copy(shuffle) phase.
  </description>
</property>

<property>
  <name>mapred.child.java.opts</name>
  <value>-XmxALLCHILDHEAPSIZEm</value>
  <description>Java opts for the task tracker child processes.  
  The following symbol, if present, will be interpolated: @taskid@ is replaced 
  by current TaskID. Any other occurrences of '@' will go unchanged.
  For example, to enable verbose gc logging to a file named for the taskid in
  /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of:
        -Xmx2560m -verbose:gc -Xloggc:/tmp/@taskid@.gc
  
  Usage of -Djava.library.path can cause programs to no longer function if
  hadoop native libraries are used. These values should instead be set as part 
  of LD_LIBRARY_PATH in the map / reduce JVM env using the mapreduce.map.env and 
  mapreduce.reduce.env config settings. 
  </description>
</property>

<property>
  <name>mapred.map.child.java.opts</name>
  <value>-XmxMAPCHILDHEAPSIZEm</value>
</property>

<property>
  <name>mapreduce.map.memory.mb</name>
  <value>MAPCONTAINERMB</value>
</property>

<property>
  <name>mapred.reduce.child.java.opts</name>
  <value>-XmxREDUCECHILDHEAPSIZEm</value>
</property>

<property>
  <name>mapreduce.reduce.memory.mb</name>
  <value>REDUCECONTAINERMB</value>
</property>

<property>
  <name>mapreduce.job.maps</name>
  <value>DEFAULTMAPTASKS</value>
  <description>The default number of map tasks per job.
  Ignored when mapreduce.jobtracker.address is "local".
  </description>
</property>

<property>
  <name>mapreduce.job.reduces</name>
  <value>DEFAULTREDUCETASKS</value>
  <description>The default number of reduce tasks per job. Typically set to 99%
  of the cluster's reduce capacity, so that if a node fails the reduces can
  still be executed in a single wave.
  Ignored when mapreduce.jobtracker.address is "local".
  </description>
</property>

<property>
  <name>mapreduce.job.reduce.slowstart.completedmaps</name>
  <value>MRSLOWSTART</value>
  <description>Fraction of the number of maps in the job which should be
  complete before reduces are scheduled for the job.
  </description>
</property>

<property>
  <name>mapreduce.task.tmp.dir</name>
  <value>${fs.default.name}/mapred/temp</value>
  <description> To set the value of tmp directory for map and reduce tasks.
  If the value is an absolute path, it is directly assigned. Otherwise, it is
  prepended with task's working directory. The java tasks are executed with
  option -Djava.io.tmpdir='the absolute path of the tmp dir'. Pipes and
  streaming are set with environment variable,
   TMPDIR='the absolute path of the tmp dir'
  </description>
</property>

<property>
  <name>mapreduce.framework.name</name>
  <value>yarn</value>
  <description>The runtime framework for executing MapReduce jobs.
  Can be one of local, classic or yarn.
  </description>
</property>

<!-- Script will calculate based on recommendation of Cloudera/Experience -->
<property>
  <name>mapreduce.jobtracker.handler.count</name>
  <value>JOBTRACKERHANDLERCOUNT</value>
  <description>
    The number of server threads for the JobTracker. This should be roughly
    4% of the number of tasktracker nodes.
  </description>
</property>

<!-- Set with recommendation of Cloudera -->
<property>
  <name>mapreduce.tasktracker.http.threads</name>
  <value>80</value>
  <description>The number of worker threads that for the http server. This is
               used for map output fetching
  </description>
</property>

<property>
  <name>yarn.app.mapreduce.am.staging-dir</name>
  <value>${hadoop.tmp.dir}/yarn/</value>
  <description>The staging dir used while submitting jobs.
  </description>  
</property>

<property>
  <name>mapreduce.job.map.output.collector.class</name>
  <value>MAPOUTPUTCOLLECTORCLASS</value>
  <description>
    It defines the MapOutputCollector implementation to use.
  </description>
</property>

<property>
  <name>mapreduce.job.reduce.shuffle.consumer.plugin.class</name>
  <value>REDUCESHUFFLECONSUMERPLUGIN</value>
  <description>
  Name of the class whose instance will be used
  to send shuffle requests by reducetasks of this job.
  The class must be an instance of org.apache.hadoop.mapred.ShuffleConsumerPlugin.
  </description>
</property>

<property>
  <name>mapreduce.output.fileoutputformat.compress</name>
  <value>HADOOPCOMPRESSION</value>
  <description>Should the job outputs be compressed?
  </description>
</property>

<property>
  <name>mapreduce.map.output.compress</name>
  <value>HADOOPCOMPRESSION</value>
  <description>Should the outputs of the maps be compressed before being
               sent across the network. Uses SequenceFile compression.
  </description>
</property>

<property>
  <name>mapreduce.jobtracker.hosts.filename</name>
  <value>HADOOPHOSTSINCLUDEFILENAME</value>
  <description>Names a file that contains the list of nodes that may
  connect to the jobtracker.  If the value is empty, all hosts are
  permitted.</description>
</property>

<property>
  <name>mapreduce.jobtracker.hosts.exclude.filename</name>
  <value>HADOOPHOSTSEXCLUDEFILENAME</value>
  <description>Names a file that contains the list of hosts that
  should be excluded by the jobtracker.  If the value is empty, no
  hosts are excluded.</description>
</property>

<property>
  <name>mapreduce.map.speculative</name>
  <value>false</value>
  <description>If true, then multiple instances of some map tasks
               may be executed in parallel.</description>
</property>

<property>
  <name>mapreduce.reduce.speculative</name>
  <value>false</value>
  <description>If true, then multiple instances of some reduce tasks
               may be executed in parallel.</description>
</property>

<!-- jobhistory properties -->

<property>
  <name>mapreduce.jobhistory.address</name>
  <value>0.0.0.0:HADOOPJOBHISTORYADDRESS</value>
  <description>MapReduce JobHistory Server IPC host:port</description>
</property>

<property>
  <name>mapreduce.jobhistory.webapp.address</name>
  <value>0.0.0.0:HADOOPJOBHISTORYWEBAPPADDRESS</value>
  <description>MapReduce JobHistory Server Web UI host:port</description>
</property>

<property>
  <name>mapreduce.client.submit.file.replication</name>
  <value>SUBMITFILEREPLICATION</value>
  <description>The replication level for submitted job files.  This
  should be around the square root of the number of nodes.
  </description>
</property>

<property>
  <name>mapreduce.job.shuffle.provider.services</name>
  <value>SHUFFLEPROVIDERSERVICES</value>
  <description>A comma-separated list of classes that should be loaded as additional ShuffleProviderPlugin(s).
    A ShuffleProviderPlugin can serve shuffle requests from reducetasks.
  </description>
</property>

<property>
  <name>mapred.rdma.cma.port</name>
  <description>Port number to be used for the RDMA connection</description>
  <value>9011</value>
</property>

<property>
  <name>mapred.rdma.wqe.per.conn</name>
  <description>
    Number of allocated Work Queue Elements (WQEs) for Receive Queue per connection
  </description>
  <value>256</value>
</property>

<property>
  <name>mapred.rdma.buf.size</name>
  <value>RDMABUFSIZE</value>
  <description>
    Used by both UdaShuffleProvider and UdaShuffleConsumer:
    - UdaShuffleProvider (TaskTracker): determines the RDMA and AIO Buffers size to satify Map Output's RDMA fetch requests
    - UdaShuffleConsumer (Reducer): user prefered RDMA buffer size for fetching map outputs
    Size in KB and must be alligned to page size.
  </description>
</property>

<property>
  <name>mapred.rdma.buf.size.min</name>
  <value>32</value>
  <description>
    UDA reducer allocates RDMA buffers according to 'mapred.rdma.buf.size'
    If the buffer size is too big then a smaller buffer will be used while 'mapred.rdma.buf.size.min' is the limit.
    Bigger RDMA buffers improves the shuffle performance. 
    Too small buffer size can sagnificantly reduce the perfomance.
    Task will fail in case the redcuer need to use smaller buffer size than 'mapred.rdma.buf.size.min'.
  </description>
</property>

<property>
  <name>mapred.rdma.shuffle.total.size</name>
  <value></value>
  <description>
    The total amount of memory per reducer allocated for UDA's RDMA shuffle phase and levitated merge algorithm.
    The value is a long number or human readable format. You can used the following suffix (case insensitive):
    k(kilo), m(mega), g(giga)
    For example: use '2g' for 2GB , or '2048m' as well, also possible using '2097152k' or just '2147483648'
    If value is not set for this parameter or value is set to 0, then the total amount of memory for RDMA will be calculated using combinatio
    n of:
    1. -Xmx on JAVA_OPTS for reducer. ( mapred.reduce.child.java.opts)
    2. mapred.job.shuffle.input.buffer.percent
    * total amount of RDMA memory per reducer will be (1)*(2)
  </description>
</property>  

<property>
  <name>mapred.rdma.compression.buffer.ratio</name>
  <description>
    The ratio in which memory is divided between RDMA buffer and decompression buffer (used only with intermediate data compression)
  </description>
  <value>0.20</value>
</property>

</configuration>

